{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "#Problem Statement:\n",
        "Combine all the seasons data from 2010 to 2025 and predict the remaining results of tthis season including the final league title winner\n",
        "\n",
        "\n",
        "**Steps**\n",
        "1.   Combine all 16 seasons of historical data (Premier League 2010-2024 and\n",
        "Championship 2024-2025).\n",
        "2.   Train a \"master model\" on this complete history.\n",
        "\n",
        "3. Load the current 2025-2026 season's fixtures.\n",
        "\n",
        "4. Simulate every remaining match of the season using the master model.\n",
        "\n",
        "5. Tally the results to produce the final predicted Premier League table for the 2025-2026 season.\n"
      ],
      "metadata": {
        "id": "SK-kHH7Dn60L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9fEvSUcm7l9",
        "outputId": "42fd3a36-90dd-4132-bbdb-2ecee22a6a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 16 historical data files.\n",
            "Master model has been trained on all available historical data.\n",
            "Generated a full fixture list of 380 matches for the 2025-2026 season.\n",
            "\n",
            "--- PREDICTED FINAL PREMIER LEAGUE TABLE 2025-2026 ---\n",
            "                       Team   P   W  D   L   GF   GA  Pts  GD\n",
            "1                  Man City  38  34  0   4  142  105  102  37\n",
            "2                   Arsenal  38  34  0   4  140  110  102  30\n",
            "3                 Liverpool  38  33  0   5  109   80   99  29\n",
            "4                   Chelsea  38  32  1   5  108   81   97  27\n",
            "5                     Spurs  38  31  1   6  107   80   94  27\n",
            "6                   Man Utd  38  31  1   6  109   84   94  25\n",
            "7                     Leeds  38  20  0  18  105  103   60   2\n",
            "8                 Newcastle  38  17  1  20  100  103   52  -3\n",
            "9    Brighton & Hove Albion  38  13  8  17   95   99   47  -4\n",
            "10           Crystal Palace  38  14  2  22  110  118   44  -8\n",
            "11                  Everton  38  13  4  21  115  124   43  -9\n",
            "12        Nottingham Forest  38  14  0  24  102  111   42  -9\n",
            "13              Bournemouth  38  14  0  24  102  113   42 -11\n",
            "14                 West Ham  38  14  0  24  102  114   42 -12\n",
            "15                Brentford  38  13  1  24  110  123   40 -13\n",
            "16                   Fulham  38  10  2  26   95  111   32 -16\n",
            "17              Aston Villa  38  10  2  26   82   98   32 -16\n",
            "18  Wolverhampton Wanderers  38  10  0  28   81  103   30 -22\n",
            "19                  Burnley  38   5  3  30   94  121   18 -27\n",
            "20               Sunderland  38   3  4  31   78  105   13 -27\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import warnings\n",
        "from itertools import permutations\n",
        "\n",
        "# Ignore potential warnings for a cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def standardize_team_name(name):\n",
        "    \"\"\"Cleans and standardizes team names to handle inconsistencies.\"\"\"\n",
        "    if not isinstance(name, str):\n",
        "        return name\n",
        "    name = name.strip()\n",
        "    mapping = {\n",
        "        'Man United': 'Man Utd', 'Manchester United': 'Man Utd',\n",
        "        'Man City': 'Man City', 'Manchester City': 'Man City',\n",
        "        'Tottenham': 'Spurs',\n",
        "        'Nott\\'m Forest': 'Nottingham Forest',\n",
        "        'West Brom': 'West Bromwich Albion',\n",
        "        'QPR': 'Queens Park Rangers',\n",
        "        'Brighton': 'Brighton & Hove Albion',\n",
        "        'Wolves': 'Wolverhampton Wanderers'\n",
        "    }\n",
        "    return mapping.get(name, name)\n",
        "\n",
        "# --- 1. Load All Historical Data (2010-2025) ---\n",
        "historical_files = [f\"/content/data/E{year}.csv\" for year in range(2010, 2025)] + [\"/content/data/E1.csv\"]\n",
        "all_dfs = []\n",
        "for f in historical_files:\n",
        "    try:\n",
        "        df = pd.read_csv(f, encoding='latin1', on_bad_lines='skip')\n",
        "        all_dfs.append(df)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: {f} not found. Skipping.\")\n",
        "\n",
        "if not all_dfs:\n",
        "    print(\"FATAL ERROR: No historical data files found. Cannot proceed.\")\n",
        "else:\n",
        "    historical_df = pd.concat(all_dfs, ignore_index=True)\n",
        "    print(f\"Successfully loaded {len(all_dfs)} historical data files.\")\n",
        "\n",
        "    # --- 2. Clean Data & Engineer Features for the Master Training Set ---\n",
        "    for col in ['HomeTeam', 'AwayTeam']:\n",
        "        historical_df[col] = historical_df[col].apply(standardize_team_name)\n",
        "\n",
        "    relevant_cols = ['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']\n",
        "    training_data = historical_df[relevant_cols].copy()\n",
        "    training_data['Date'] = pd.to_datetime(training_data['Date'], dayfirst=True, errors='coerce')\n",
        "    training_data.dropna(subset=['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR'], inplace=True)\n",
        "    training_data = training_data.sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "    def get_form_stats(team, date, hist_df):\n",
        "        \"\"\"Calculates a team's average goals scored and conceded in their last 5 games.\"\"\"\n",
        "        team_df = hist_df[(hist_df['HomeTeam'] == team) | (hist_df['AwayTeam'] == team)]\n",
        "        past_games = team_df[team_df['Date'] < date].tail(5)\n",
        "        if len(past_games) < 5: return 1.0, 1.0\n",
        "        goals_scored = past_games.apply(lambda r: r['FTHG'] if r['HomeTeam'] == team else r['FTAG'], axis=1).mean()\n",
        "        goals_conceded = past_games.apply(lambda r: r['FTAG'] if r['HomeTeam'] == team else r['FTHG'], axis=1).mean()\n",
        "        return goals_scored, goals_conceded\n",
        "\n",
        "    form_features = [get_form_stats(r['HomeTeam'], r['Date'], training_data) + get_form_stats(r['AwayTeam'], r['Date'], training_data) for _, r in training_data.iterrows()]\n",
        "    training_data = pd.concat([training_data, pd.DataFrame(form_features, columns=['H_GS', 'H_GC', 'A_GS', 'A_GC'])], axis=1).dropna()\n",
        "\n",
        "    # --- 3. Train the Master Prediction Model ---\n",
        "    feature_cols = ['HomeTeam', 'AwayTeam', 'H_GS', 'H_GC', 'A_GS', 'A_GC']\n",
        "    X_train_raw = training_data[feature_cols]\n",
        "    y_train = training_data['FTR']\n",
        "    X_train = pd.get_dummies(X_train_raw, columns=['HomeTeam', 'AwayTeam'])\n",
        "\n",
        "    master_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "    master_model.fit(X_train, y_train)\n",
        "    print(\"Master model has been trained on all available historical data.\")\n",
        "\n",
        "    # --- 4. Generate the Full 2025-2026 Season Fixture List ---\n",
        "    try:\n",
        "        fixtures_25_26_orig = pd.read_csv(\"/content/data/E2025.csv\", encoding='latin1', on_bad_lines='skip')\n",
        "        for col in ['HomeTeam', 'AwayTeam']:\n",
        "            fixtures_25_26_orig[col] = fixtures_25_26_orig[col].apply(standardize_team_name)\n",
        "        fixtures_25_26_orig['Date'] = pd.to_datetime(fixtures_25_26_orig['Date'], dayfirst=True, errors='coerce')\n",
        "\n",
        "        teams_25_26 = pd.concat([fixtures_25_26_orig['HomeTeam'], fixtures_25_26_orig['AwayTeam']]).unique()\n",
        "\n",
        "        if len(teams_25_26) < 20:\n",
        "             print(\"\\nWarning: Fewer than 20 teams found in E2025.csv. The generated fixture list may be incomplete.\")\n",
        "\n",
        "        # Generate all possible home/away combinations\n",
        "        all_possible_fixtures = list(permutations(teams_25_26, 2))\n",
        "\n",
        "        # Create a DataFrame of all 380 possible matches\n",
        "        full_fixture_list = pd.DataFrame(all_possible_fixtures, columns=['HomeTeam', 'AwayTeam'])\n",
        "\n",
        "        # Merge with the original file to keep the matches that have already been played\n",
        "        # We use a left merge to keep all generated fixtures, and an indicator to see which ones already exist\n",
        "        season_fixtures = pd.merge(full_fixture_list, fixtures_25_26_orig, on=['HomeTeam', 'AwayTeam'], how='left', indicator=True)\n",
        "\n",
        "        # Fixtures that haven't been played yet need a placeholder date to allow the simulation to proceed\n",
        "        last_known_date = season_fixtures['Date'].max()\n",
        "        if pd.isna(last_known_date): last_known_date = pd.to_datetime('today') # Fallback if no dates exist\n",
        "\n",
        "        # Assign incremental dates to unplayed fixtures\n",
        "        unplayed_mask = season_fixtures['_merge'] == 'left_only'\n",
        "        num_unplayed = unplayed_mask.sum()\n",
        "        placeholder_dates = pd.to_datetime([last_known_date + pd.Timedelta(days=i*7) for i in range(1, (num_unplayed // 10) + 2) for _ in range(10)])[:num_unplayed]\n",
        "        season_fixtures.loc[unplayed_mask, 'Date'] = placeholder_dates\n",
        "\n",
        "        season_fixtures.sort_values(by='Date', inplace=True)\n",
        "        season_fixtures.drop(columns=['_merge'], inplace=True)\n",
        "\n",
        "        print(f\"Generated a full fixture list of {len(season_fixtures)} matches for the 2025-2026 season.\")\n",
        "\n",
        "        # --- 5. Simulate the Full Season ---\n",
        "        live_history = training_data.copy()\n",
        "        league_table = {team: {'P': 0, 'W': 0, 'D': 0, 'L': 0, 'GF': 0, 'GA': 0, 'Pts': 0} for team in teams_25_26}\n",
        "\n",
        "        for _, fixture in season_fixtures.iterrows():\n",
        "            h_team, a_team, date = fixture['HomeTeam'], fixture['AwayTeam'], fixture['Date']\n",
        "\n",
        "            # Use actual result if it's in the original file\n",
        "            if pd.notna(fixture['FTR']):\n",
        "                res, hg, ag = fixture['FTR'], int(fixture['FTHG']), int(fixture['FTAG'])\n",
        "            # Predict if result is missing\n",
        "            else:\n",
        "                h_gs, h_gc = get_form_stats(h_team, date, live_history)\n",
        "                a_gs, a_gc = get_form_stats(a_team, date, live_history)\n",
        "\n",
        "                match_data = pd.DataFrame([[h_team, a_team, h_gs, h_gc, a_gs, a_gc]], columns=feature_cols)\n",
        "                match_data_encoded = pd.get_dummies(match_data, columns=['HomeTeam', 'AwayTeam'])\n",
        "                match_data_aligned = match_data_encoded.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "                res = master_model.predict(match_data_aligned)[0]\n",
        "\n",
        "                # Estimate goals for the table\n",
        "                hg = int(round((h_gs + a_gc) / 2)); ag = int(round((a_gs + h_gc) / 2))\n",
        "                if res == 'H': hg = max(hg, ag + 1)\n",
        "                elif res == 'A': ag = max(ag, hg + 1)\n",
        "                else: hg = ag = max(hg, ag)\n",
        "\n",
        "            # Update league table\n",
        "            for team, gf, ga, r in [(h_team, hg, ag, res), (a_team, ag, hg, res)]:\n",
        "                if team in league_table:\n",
        "                    league_table[team]['P'] += 1; league_table[team]['GF'] += gf; league_table[team]['GA'] += ga\n",
        "                    if (team == h_team and r == 'H') or (team == a_team and r == 'A'):\n",
        "                        league_table[team]['W'] += 1; league_table[team]['Pts'] += 3\n",
        "                    elif r == 'D':\n",
        "                        league_table[team]['D'] += 1; league_table[team]['Pts'] += 1\n",
        "                    else:\n",
        "                        league_table[team]['L'] += 1\n",
        "\n",
        "            # Add result to history to influence future predictions\n",
        "            new_row = pd.DataFrame([{'Date': date, 'HomeTeam': h_team, 'AwayTeam': a_team, 'FTHG': hg, 'FTAG': ag, 'FTR': res}])\n",
        "            live_history = pd.concat([live_history, new_row], ignore_index=True)\n",
        "\n",
        "        # --- 6. Display Final Predicted Table ---\n",
        "        final_table = pd.DataFrame.from_dict(league_table, orient='index')\n",
        "        final_table['GD'] = final_table['GF'] - final_table['GA']\n",
        "        final_table = final_table.sort_values(by=['Pts', 'GD', 'GF'], ascending=False).reset_index().rename(columns={'index': 'Team'})\n",
        "        final_table.index += 1\n",
        "\n",
        "        print(\"\\n--- PREDICTED FINAL PREMIER LEAGUE TABLE 2025-2026 ---\")\n",
        "        print(final_table.to_string())\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"\\nFATAL ERROR: The 2025-2026 season file (E2025.csv) was not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "# Ignore potential warnings for a cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def standardize_team_name(name):\n",
        "    \"\"\"Cleans and standardizes team names to handle inconsistencies.\"\"\"\n",
        "    if not isinstance(name, str):\n",
        "        return name\n",
        "    name = name.strip()\n",
        "    mapping = {\n",
        "        'Man United': 'Man Utd', 'Manchester United': 'Man Utd',\n",
        "        'Man City': 'Man City', 'Manchester City': 'Man City',\n",
        "        'Tottenham': 'Spurs',\n",
        "        'Nott\\'m Forest': 'Nottingham Forest',\n",
        "        'West Brom': 'West Bromwich Albion',\n",
        "        'QPR': 'Queens Park Rangers',\n",
        "        'Brighton': 'Brighton & Hove Albion',\n",
        "        'Wolves': 'Wolverhampton Wanderers'\n",
        "    }\n",
        "    return mapping.get(name, name)\n",
        "\n",
        "# --- 1. Load and Prepare All Historical Data ---\n",
        "historical_files = [f\"/content/data/E{year}.csv\" for year in range(2010, 2025)] + [\"/content/data/E1.csv\"]\n",
        "all_dfs = []\n",
        "for f in historical_files:\n",
        "    try:\n",
        "        df = pd.read_csv(f, encoding='latin1', on_bad_lines='skip')\n",
        "        all_dfs.append(df)\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "\n",
        "if not all_dfs:\n",
        "    print(\"FATAL ERROR: No historical data files found. Cannot proceed.\")\n",
        "else:\n",
        "    historical_df = pd.concat(all_dfs, ignore_index=True)\n",
        "    print(f\"Successfully loaded {len(all_dfs)} historical data files.\")\n",
        "\n",
        "    # --- 2. Clean Data & Engineer Features ---\n",
        "    for col in ['HomeTeam', 'AwayTeam']:\n",
        "        historical_df[col] = historical_df[col].apply(standardize_team_name)\n",
        "\n",
        "    relevant_cols = ['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']\n",
        "    full_data = historical_df[relevant_cols].copy()\n",
        "    full_data['Date'] = pd.to_datetime(full_data['Date'], dayfirst=True, errors='coerce')\n",
        "    full_data.dropna(subset=['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR'], inplace=True)\n",
        "    full_data = full_data.sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "    def get_form_stats(team, date, hist_df):\n",
        "        \"\"\"Calculates a team's average goals scored and conceded in their last 5 games.\"\"\"\n",
        "        team_df = hist_df[(hist_df['HomeTeam'] == team) | (hist_df['AwayTeam'] == team)]\n",
        "        past_games = team_df[team_df['Date'] < date].tail(5)\n",
        "        if len(past_games) < 5: return 1.0, 1.0\n",
        "        goals_scored = past_games.apply(lambda r: r['FTHG'] if r['HomeTeam'] == team else r['FTAG'], axis=1).mean()\n",
        "        goals_conceded = past_games.apply(lambda r: r['FTAG'] if r['HomeTeam'] == team else r['FTHG'], axis=1).mean()\n",
        "        return goals_scored, goals_conceded\n",
        "\n",
        "    form_features = [get_form_stats(r['HomeTeam'], r['Date'], full_data) + get_form_stats(r['AwayTeam'], r['Date'], full_data) for _, r in full_data.iterrows()]\n",
        "    full_data = pd.concat([full_data, pd.DataFrame(form_features, columns=['H_GS', 'H_GC', 'A_GS', 'A_GC'])], axis=1)\n",
        "    full_data.dropna(inplace=True)\n",
        "\n",
        "    # --- 3. Split Data, Train, and Evaluate ---\n",
        "    feature_cols = ['HomeTeam', 'AwayTeam', 'H_GS', 'H_GC', 'A_GS', 'A_GC']\n",
        "    X = full_data[feature_cols]\n",
        "    y = full_data['FTR']\n",
        "\n",
        "    # One-Hot Encode the team names\n",
        "    X_encoded = pd.get_dummies(X, columns=['HomeTeam', 'AwayTeam'])\n",
        "\n",
        "    # **THIS IS THE KEY STEP**: Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    print(f\"\\nData split into {len(X_train)} training samples and {len(X_test)} testing samples.\")\n",
        "\n",
        "    # Initialize and train the model ONLY on the training data\n",
        "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # --- 4. Compare Performance ---\n",
        "    # Make predictions on both sets\n",
        "    preds_on_train = model.predict(X_train)\n",
        "    preds_on_test = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy on both sets\n",
        "    accuracy_train = accuracy_score(y_train, preds_on_train)\n",
        "    accuracy_test = accuracy_score(y_test, preds_on_test)\n",
        "\n",
        "    print(\"\\n--- Overfitting Analysis ---\")\n",
        "    print(f\"Accuracy on Training Data (seen data): {accuracy_train:.2%}\")\n",
        "    print(f\"Accuracy on Testing Data (unseen data): {accuracy_test:.2%}\")\n",
        "\n",
        "    difference = abs(accuracy_train - accuracy_test) * 100\n",
        "    print(f\"\\nDifference: {difference:.2f}%\")\n",
        "\n",
        "    if difference < 5:\n",
        "        print(\"\\nConclusion: The model is generalizing well. There is no significant sign of overfitting. 👍\")\n",
        "    else:\n",
        "        print(\"\\nConclusion: The model may be overfitting. The performance on seen data is notably higher than on unseen data. 👎\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi486HBqrY7-",
        "outputId": "24fd7dda-4c5f-4863-9f7b-152e0a065646"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 16 historical data files.\n",
            "\n",
            "Data split into 5001 training samples and 1251 testing samples.\n",
            "\n",
            "--- Overfitting Analysis ---\n",
            "Accuracy on Training Data (seen data): 54.15%\n",
            "Accuracy on Testing Data (unseen data): 52.20%\n",
            "\n",
            "Difference: 1.95%\n",
            "\n",
            "Conclusion: The model is generalizing well. There is no significant sign of overfitting. 👍\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W-nBx2aurYov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "#Testing Out Different Other Models\n",
        "We will test 8 different machine learning models, including industry-standard ones like XGBoost and LightGBM.\n",
        "\n",
        "**Robust Evaluation**: We'll measure each model on four key metrics: Accuracy, Precision, Recall, and F1-Score. This gives a much more complete picture of performance than just accuracy alone.\n",
        "\n",
        "**Top 3 Showdown**: After evaluating, we'll identify the top 3 performing models. I will then provide you with a final script to generate the predicted 2025-2026 league table for each of those top 3 models so you can compare their final predictions."
      ],
      "metadata": {
        "id": "Hj9pyW3Ft2Be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from itertools import permutations\n",
        "\n",
        "# Scikit-learn Models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Modern Boosting Libraries (you may need to !pip install xgboost lightgbm)\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Ignore potential warnings for a cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def standardize_team_name(name):\n",
        "    \"\"\"Cleans and standardizes team names to handle inconsistencies.\"\"\"\n",
        "    if not isinstance(name, str): return name\n",
        "    name = name.strip()\n",
        "    mapping = {\n",
        "        'Man United': 'Man Utd', 'Manchester United': 'Man Utd',\n",
        "        'Man City': 'Man City', 'Manchester City': 'Man City',\n",
        "        'Tottenham': 'Spurs',\n",
        "        'Nott\\'m Forest': 'Nottingham Forest',\n",
        "        'West Brom': 'West Bromwich Albion',\n",
        "        'QPR': 'Queens Park Rangers',\n",
        "        'Brighton': 'Brighton & Hove Albion',\n",
        "        'Wolves': 'Wolverhampton Wanderers'\n",
        "    }\n",
        "    return mapping.get(name, name)\n",
        "\n",
        "# --- 1. Load and Prepare All Historical Data ---\n",
        "historical_files = [f\"/content/data/E{year}.csv\" for year in range(2010, 2025)] + [\"/content/data/E1.csv\"]\n",
        "all_dfs = []\n",
        "for f in historical_files:\n",
        "    try:\n",
        "        df = pd.read_csv(f, encoding='latin1', on_bad_lines='skip')\n",
        "        all_dfs.append(df)\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "\n",
        "if not all_dfs:\n",
        "    print(\"FATAL ERROR: No historical data files found. Cannot proceed.\")\n",
        "else:\n",
        "    historical_df = pd.concat(all_dfs, ignore_index=True)\n",
        "    print(f\"Successfully loaded {len(all_dfs)} historical data files.\")\n",
        "\n",
        "    # --- 2. Clean Data & Engineer Features ---\n",
        "    for col in ['HomeTeam', 'AwayTeam']:\n",
        "        historical_df[col] = historical_df[col].apply(standardize_team_name)\n",
        "\n",
        "    relevant_cols = ['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']\n",
        "    full_data = historical_df[relevant_cols].copy()\n",
        "    full_data['Date'] = pd.to_datetime(full_data['Date'], dayfirst=True, errors='coerce')\n",
        "    full_data.dropna(subset=['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR'], inplace=True)\n",
        "    full_data = full_data.sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "    def get_form_stats(team, date, hist_df):\n",
        "        \"\"\"Calculates a team's average goals scored and conceded in their last 5 games.\"\"\"\n",
        "        team_df = hist_df[(hist_df['HomeTeam'] == team) | (hist_df['AwayTeam'] == team)]\n",
        "        past_games = team_df[team_df['Date'] < date].tail(5)\n",
        "        if len(past_games) < 5: return 1.0, 1.0\n",
        "        goals_scored = past_games.apply(lambda r: r['FTHG'] if r['HomeTeam'] == team else r['FTAG'], axis=1).mean()\n",
        "        goals_conceded = past_games.apply(lambda r: r['FTAG'] if r['HomeTeam'] == team else r['FTHG'], axis=1).mean()\n",
        "        return goals_scored, goals_conceded\n",
        "\n",
        "    form_features = [get_form_stats(r['HomeTeam'], r['Date'], full_data) + get_form_stats(r['AwayTeam'], r['Date'], full_data) for _, r in full_data.iterrows()]\n",
        "    full_data = pd.concat([full_data, pd.DataFrame(form_features, columns=['H_GS', 'H_GC', 'A_GS', 'A_GC'])], axis=1).dropna()\n",
        "\n",
        "    # --- 3. Prepare Data for Modeling ---\n",
        "    feature_cols = ['HomeTeam', 'AwayTeam', 'H_GS', 'H_GC', 'A_GS', 'A_GC']\n",
        "    X = full_data[feature_cols]\n",
        "    y = full_data['FTR']\n",
        "\n",
        "    # Map string labels ('H', 'D', 'A') to integers (2, 1, 0) for model compatibility\n",
        "    label_mapping = {'H': 2, 'D': 1, 'A': 0}\n",
        "    y = y.map(label_mapping)\n",
        "\n",
        "    # One-Hot Encode the team names\n",
        "    X_encoded = pd.get_dummies(X, columns=['HomeTeam', 'AwayTeam'])\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    # --- 4. Define and Train All Models ---\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "        \"XGBoost\": xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'),\n",
        "        \"LightGBM\": lgb.LGBMClassifier(random_state=42),\n",
        "        \"Support Vector Machine\": SVC(random_state=42),\n",
        "        \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "        \"Gaussian Naive Bayes\": GaussianNB()\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    print(\"\\nTraining and evaluating models...\")\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, preds)\n",
        "        precision = precision_score(y_test, preds, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_test, preds, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
        "\n",
        "        results[name] = [accuracy, precision, recall, f1]\n",
        "        print(f\" ✓ {name} evaluated.\")\n",
        "\n",
        "    # --- 5. Display Comparative Results ---\n",
        "    results_df = pd.DataFrame.from_dict(results, orient='index',\n",
        "                                        columns=['Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
        "\n",
        "    results_df = results_df.sort_values(by=\"F1-Score\", ascending=False)\n",
        "\n",
        "    print(\"\\n--- MODEL PERFORMANCE COMPARISON ---\")\n",
        "    print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anpPbC8st9TW",
        "outputId": "8ad86e91-5d77-4758-d959-c2e5b0d6b85b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 16 historical data files.\n",
            "\n",
            "Training and evaluating models...\n",
            " ✓ Logistic Regression evaluated.\n",
            " ✓ Random Forest evaluated.\n",
            " ✓ Gradient Boosting evaluated.\n",
            " ✓ XGBoost evaluated.\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 241\n",
            "[LightGBM] [Info] Number of data points in the train set: 5001, number of used features: 82\n",
            "[LightGBM] [Info] Start training from score -1.182411\n",
            "[LightGBM] [Info] Start training from score -1.410787\n",
            "[LightGBM] [Info] Start training from score -0.799597\n",
            " ✓ LightGBM evaluated.\n",
            " ✓ Support Vector Machine evaluated.\n",
            " ✓ K-Nearest Neighbors evaluated.\n",
            " ✓ Gaussian Naive Bayes evaluated.\n",
            "\n",
            "--- MODEL PERFORMANCE COMPARISON ---\n",
            "                        Accuracy  Precision    Recall  F1-Score\n",
            "Gaussian Naive Bayes    0.492406   0.495678  0.492406  0.477386\n",
            "Logistic Regression     0.521982   0.494722  0.521982  0.466595\n",
            "LightGBM                0.500400   0.464208  0.500400  0.465455\n",
            "XGBoost                 0.497202   0.461513  0.497202  0.464700\n",
            "Random Forest           0.495604   0.446883  0.495604  0.451979\n",
            "Gradient Boosting       0.511591   0.479238  0.511591  0.448067\n",
            "K-Nearest Neighbors     0.438050   0.436124  0.438050  0.434147\n",
            "Support Vector Machine  0.505196   0.461817  0.505196  0.424739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Top 3 Performing models based on their F1 Score\n",
        "\n",
        "Gaussian Naive Bayes (F1-Score: 0.477)\n",
        "\n",
        "Logistic Regression (F1-Score: 0.467)\n",
        "\n",
        "LightGBM (F1-Score: 0.465)\n"
      ],
      "metadata": {
        "id": "OWNWWuUBv9in"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "import warnings\n",
        "from itertools import permutations\n",
        "\n",
        "# Ignore potential warnings for a cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def standardize_team_name(name):\n",
        "    \"\"\"Cleans to handle inconsistencies\"\"\"\n",
        "    if not isinstance(name, str): return name\n",
        "    name = name.strip()\n",
        "    mapping = {\n",
        "        'Man United': 'Man Utd', 'Manchester United': 'Man Utd',\n",
        "        'Man City': 'Man City', 'Manchester City': 'Man City',\n",
        "        'Tottenham': 'Spurs',\n",
        "        'Nott\\'m Forest': 'Nottingham Forest',\n",
        "        'West Brom': 'West Bromwich Albion',\n",
        "        'QPR': 'Queens Park Rangers',\n",
        "        'Brighton': 'Brighton & Hove Albion',\n",
        "        'Wolves': 'Wolverhampton Wanderers'\n",
        "    }\n",
        "    return mapping.get(name, name)\n",
        "\n",
        "def get_form_stats(team, date, hist_df):\n",
        "    \"\"\"Calculates a team's average goals scored and conceded in their last 5 games.\"\"\"\n",
        "    team_df = hist_df[(hist_df['HomeTeam'] == team) | (hist_df['AwayTeam'] == team)]\n",
        "    past_games = team_df[team_df['Date'] < date].tail(5)\n",
        "    if len(past_games) < 5: return 1.0, 1.0 # Return neutral form if not enough data\n",
        "    goals_scored = past_games.apply(lambda r: r['FTHG'] if r['HomeTeam'] == team else r['FTAG'], axis=1).mean()\n",
        "    goals_conceded = past_games.apply(lambda r: r['FTAG'] if r['HomeTeam'] == team else r['FTHG'], axis=1).mean()\n",
        "    return goals_scored, goals_conceded\n",
        "\n",
        "# --- Main Simulation Logic ---\n",
        "# 1. Load and prepare the full historical dataset\n",
        "historical_files = [f\"/content/data/E{year}.csv\" for year in range(2010, 2025)] + [\"/content/data/E1.csv\"]\n",
        "all_dfs = []\n",
        "for f in historical_files:\n",
        "    try:\n",
        "        df = pd.read_csv(f, encoding='latin1', on_bad_lines='skip')\n",
        "        all_dfs.append(df)\n",
        "    except FileNotFoundError: pass\n",
        "historical_df = pd.concat(all_dfs, ignore_index=True)\n",
        "for col in ['HomeTeam', 'AwayTeam']:\n",
        "    historical_df[col] = historical_df[col].apply(standardize_team_name)\n",
        "relevant_cols = ['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']\n",
        "training_data = historical_df[relevant_cols].copy()\n",
        "training_data['Date'] = pd.to_datetime(training_data['Date'], dayfirst=True, errors='coerce')\n",
        "training_data.dropna(subset=['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR'], inplace=True)\n",
        "training_data = training_data.sort_values(by='Date').reset_index(drop=True)\n",
        "form_features = [get_form_stats(r['HomeTeam'], r['Date'], training_data) + get_form_stats(r['AwayTeam'], r['Date'], training_data) for _, r in training_data.iterrows()]\n",
        "training_data = pd.concat([training_data, pd.DataFrame(form_features, columns=['H_GS', 'H_GC', 'A_GS', 'A_GC'])], axis=1).dropna()\n",
        "\n",
        "# 2. Prepare the final training data\n",
        "feature_cols = ['HomeTeam', 'AwayTeam', 'H_GS', 'H_GC', 'A_GS', 'A_GC']\n",
        "X_train_raw = training_data[feature_cols]\n",
        "y_train = training_data['FTR']\n",
        "\n",
        "# Map string labels to integers for models that require it\n",
        "label_mapping = {'H': 2, 'D': 1, 'A': 0}\n",
        "y_train_mapped = y_train.map(label_mapping)\n",
        "X_train = pd.get_dummies(X_train_raw, columns=['HomeTeam', 'AwayTeam'])\n",
        "\n",
        "# ---  Top 3 Models from previous train and test ---\n",
        "# This dictionary has been updated with your top 3 models based on the F1-Score.\n",
        "top_3_models = {\n",
        "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"LightGBM\": lgb.LGBMClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# 3. Train the top models and run a simulation for each\n",
        "for model_name, model in top_3_models.items():\n",
        "    print(f\"\\n--- Running Simulation for: {model_name} ---\")\n",
        "\n",
        "    # Train the model on the entire historical dataset\n",
        "    # Naive Bayes doesn't use random_state. Other models need integer labels.\n",
        "    if \"Naive Bayes\" in model_name:\n",
        "         model.fit(X_train, y_train) # Naive Bayes can handle string labels if needed, but we'll be consistent\n",
        "    else:\n",
        "         model.fit(X_train, y_train_mapped)\n",
        "\n",
        "    # Load and generate the full fixture list for 2025-2026\n",
        "    fixtures_25_26_orig = pd.read_csv(\"/content/data/E2025.csv\", encoding='latin1', on_bad_lines='skip')\n",
        "    for col in ['HomeTeam', 'AwayTeam']:\n",
        "        fixtures_25_26_orig[col] = fixtures_25_26_orig[col].apply(standardize_team_name)\n",
        "    fixtures_25_26_orig['Date'] = pd.to_datetime(fixtures_25_26_orig['Date'], dayfirst=True, errors='coerce')\n",
        "    teams_25_26 = pd.concat([fixtures_25_26_orig['HomeTeam'], fixtures_25_26_orig['AwayTeam']]).unique()\n",
        "    all_possible_fixtures = list(permutations(teams_25_26, 2))\n",
        "    full_fixture_list = pd.DataFrame(all_possible_fixtures, columns=['HomeTeam', 'AwayTeam'])\n",
        "    season_fixtures = pd.merge(full_fixture_list, fixtures_25_26_orig, on=['HomeTeam', 'AwayTeam'], how='left', indicator=True)\n",
        "    last_known_date = season_fixtures['Date'].max()\n",
        "    if pd.isna(last_known_date): last_known_date = pd.to_datetime('today')\n",
        "    unplayed_mask = season_fixtures['_merge'] == 'left_only'\n",
        "    num_unplayed = unplayed_mask.sum()\n",
        "    placeholder_dates = pd.to_datetime([last_known_date + pd.Timedelta(days=i*7) for i in range(1, (num_unplayed // 10) + 2) for _ in range(10)])[:num_unplayed]\n",
        "    season_fixtures.loc[unplayed_mask, 'Date'] = placeholder_dates\n",
        "    season_fixtures.sort_values(by='Date', inplace=True)\n",
        "    season_fixtures.drop(columns=['_merge'], inplace=True)\n",
        "\n",
        "    # Run the simulation\n",
        "    live_history = training_data.copy()\n",
        "    league_table = {team: {'P': 0, 'W': 0, 'D': 0, 'L': 0, 'GF': 0, 'GA': 0, 'Pts': 0} for team in teams_25_26}\n",
        "\n",
        "    # Create an inverse mapping to convert predictions back to 'H', 'D', 'A'\n",
        "    inverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "    for _, fixture in season_fixtures.iterrows():\n",
        "        h_team, a_team, date = fixture['HomeTeam'], fixture['AwayTeam'], fixture['Date']\n",
        "        if pd.notna(fixture['FTR']):\n",
        "            res, hg, ag = fixture['FTR'], int(fixture['FTHG']), int(fixture['FTAG'])\n",
        "        else:\n",
        "            h_gs, h_gc = get_form_stats(h_team, date, live_history)\n",
        "            a_gs, a_gc = get_form_stats(a_team, date, live_history)\n",
        "            match_data = pd.DataFrame([[h_team, a_team, h_gs, h_gc, a_gs, a_gc]], columns=feature_cols)\n",
        "            match_data_encoded = pd.get_dummies(match_data, columns=['HomeTeam', 'AwayTeam'])\n",
        "            match_data_aligned = match_data_encoded.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "            # Get the numeric prediction and convert it back to a string label\n",
        "            numeric_pred = model.predict(match_data_aligned)[0]\n",
        "            res = inverse_label_mapping.get(numeric_pred, 'D') # Default to Draw if something goes wrong\n",
        "\n",
        "            hg = int(round((h_gs + a_gc) / 2)); ag = int(round((a_gs + h_gc) / 2))\n",
        "            if res == 'H': hg = max(hg, ag + 1)\n",
        "            elif res == 'A': ag = max(ag, hg + 1)\n",
        "            else: hg = ag = max(hg, ag)\n",
        "\n",
        "        for team, gf, ga, r in [(h_team, hg, ag, res), (a_team, ag, hg, res)]:\n",
        "            if team in league_table:\n",
        "                league_table[team]['P'] += 1; league_table[team]['GF'] += gf; league_table[team]['GA'] += ga\n",
        "                if (team == h_team and r == 'H') or (team == a_team and r == 'A'):\n",
        "                    league_table[team]['W'] += 1; league_table[team]['Pts'] += 3\n",
        "                elif r == 'D':\n",
        "                    league_table[team]['D'] += 1; league_table[team]['Pts'] += 1\n",
        "                else: league_table[team]['L'] += 1\n",
        "\n",
        "        new_row = pd.DataFrame([{'Date': date, 'HomeTeam': h_team, 'AwayTeam': a_team, 'FTHG': hg, 'FTAG': ag, 'FTR': res}])\n",
        "        live_history = pd.concat([live_history, new_row], ignore_index=True)\n",
        "\n",
        "    # Display the final table for the current model\n",
        "    final_table = pd.DataFrame.from_dict(league_table, orient='index')\n",
        "    final_table['GD'] = final_table['GF'] - final_table['GA']\n",
        "    final_table = final_table.sort_values(by=['Pts', 'GD', 'GF'], ascending=False).reset_index().rename(columns={'index': 'Team'})\n",
        "    final_table.index += 1\n",
        "\n",
        "    print(f\"\\n--- PREDICTED FINAL TABLE ({model_name}) ---\")\n",
        "    print(final_table.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKwGObexvv1p",
        "outputId": "13f1a924-b3b3-4cef-a903-fa11420f6f66"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Simulation for: Gaussian Naive Bayes ---\n",
            "\n",
            "--- PREDICTED FINAL TABLE (Gaussian Naive Bayes) ---\n",
            "                       Team   P  W   D  L  GF  GA  Pts  GD\n",
            "1                  Man City  38  1  37  0  78  74   40   4\n",
            "2                     Spurs  38  1  37  0  76  73   40   3\n",
            "3                Sunderland  38  1  37  0  74  71   40   3\n",
            "4                 Liverpool  38  1  37  0  77  75   40   2\n",
            "5         Nottingham Forest  38  1  37  0  77  75   40   2\n",
            "6                     Leeds  38  1  37  0  75  74   40   1\n",
            "7                   Arsenal  38  1  37  0  75  74   40   1\n",
            "8                    Fulham  38  0  38  0  75  75   38   0\n",
            "9    Brighton & Hove Albion  38  0  38  0  74  74   38   0\n",
            "10           Crystal Palace  38  0  38  0  74  74   38   0\n",
            "11              Aston Villa  38  0  38  0  71  71   38   0\n",
            "12                  Chelsea  38  0  38  0  71  71   38   0\n",
            "13                Newcastle  38  0  38  0  68  68   38   0\n",
            "14                  Everton  38  0  37  1  74  75   37  -1\n",
            "15                  Man Utd  38  0  37  1  73  74   37  -1\n",
            "16              Bournemouth  38  0  37  1  76  78   37  -2\n",
            "17                Brentford  38  0  37  1  75  77   37  -2\n",
            "18                 West Ham  38  0  37  1  74  77   37  -3\n",
            "19                  Burnley  38  0  37  1  74  77   37  -3\n",
            "20  Wolverhampton Wanderers  38  0  37  1  73  77   37  -4\n",
            "\n",
            "--- Running Simulation for: Logistic Regression ---\n",
            "\n",
            "--- PREDICTED FINAL TABLE (Logistic Regression) ---\n",
            "                       Team   P   W  D   L   GF   GA  Pts  GD\n",
            "1                  Man City  38  34  0   4  142  105  102  37\n",
            "2                   Arsenal  38  34  0   4  140  110  102  30\n",
            "3                 Liverpool  38  33  0   5  109   80   99  29\n",
            "4                   Chelsea  38  32  1   5  108   81   97  27\n",
            "5                     Spurs  38  31  1   6  107   80   94  27\n",
            "6                   Man Utd  38  31  1   6  109   84   94  25\n",
            "7                     Leeds  38  20  0  18  105  103   60   2\n",
            "8                 Newcastle  38  17  1  20  100  103   52  -3\n",
            "9    Brighton & Hove Albion  38  13  8  17   95   99   47  -4\n",
            "10           Crystal Palace  38  14  2  22  110  118   44  -8\n",
            "11                  Everton  38  13  4  21  115  124   43  -9\n",
            "12        Nottingham Forest  38  14  0  24  102  111   42  -9\n",
            "13              Bournemouth  38  14  0  24  102  113   42 -11\n",
            "14                 West Ham  38  14  0  24  102  114   42 -12\n",
            "15                Brentford  38  13  1  24  110  123   40 -13\n",
            "16                   Fulham  38  10  2  26   95  111   32 -16\n",
            "17              Aston Villa  38  10  2  26   82   98   32 -16\n",
            "18  Wolverhampton Wanderers  38  10  0  28   81  103   30 -22\n",
            "19                  Burnley  38   5  3  30   94  121   18 -27\n",
            "20               Sunderland  38   3  4  31   78  105   13 -27\n",
            "\n",
            "--- Running Simulation for: LightGBM ---\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 271\n",
            "[LightGBM] [Info] Number of data points in the train set: 6252, number of used features: 96\n",
            "[LightGBM] [Info] Start training from score -1.182662\n",
            "[LightGBM] [Info] Start training from score -1.410907\n",
            "[LightGBM] [Info] Start training from score -0.799361\n",
            "\n",
            "--- PREDICTED FINAL TABLE (LightGBM) ---\n",
            "                       Team   P   W   D   L   GF   GA  Pts  GD\n",
            "1                  Man City  38  34   2   2  154  119  104  35\n",
            "2                 Liverpool  38  34   2   2  119   86  104  33\n",
            "3                   Man Utd  38  31   2   5  118   92   95  26\n",
            "4                   Chelsea  38  30   2   6  117   93   92  24\n",
            "5                   Arsenal  38  29   2   7  154  132   89  22\n",
            "6                     Spurs  38  25   1  12  120  105   76  15\n",
            "7         Nottingham Forest  38  17   8  13  108  103   59   5\n",
            "8                Sunderland  38  19   2  17  105  101   59   4\n",
            "9   Wolverhampton Wanderers  38  17   4  17  105  108   55  -3\n",
            "10              Aston Villa  38  17   2  19   96   98   53  -2\n",
            "11   Brighton & Hove Albion  38  10  17  11   98   99   47  -1\n",
            "12                    Leeds  38  15   2  21  115  121   47  -6\n",
            "13                Newcastle  38  11   4  23  118  130   37 -12\n",
            "14              Bournemouth  38   9   7  22  118  132   34 -14\n",
            "15                Brentford  38  10   0  28  138  157   30 -19\n",
            "16                   Fulham  38   9   1  28  123  142   28 -19\n",
            "17                  Burnley  38   8   3  27  120  141   27 -21\n",
            "18                 West Ham  38   8   2  28  119  141   26 -22\n",
            "19           Crystal Palace  38   6   5  27  123  144   23 -21\n",
            "20                  Everton  38   4   6  28  128  152   18 -24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gG6k1TsXvvDq"
      }
    }
  ]
}